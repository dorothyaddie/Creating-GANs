{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating GANs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An independent project by Esa Schenck, Dorothy \"Addie\" Addie, Zampa Provenzale conducted during SURF 2021. Our goal is to create a GAN that is able to draw images of left and right dorsal and palm facing hands. This is the first part of our independent project, Creating GANs. Our goal for this notebook is to create a neural network that will be able to recognize right and left dorsal and palm facing pictures of hands. We used the [11k Hand Dataset](https://sites.google.com/view/11khands)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Data Processing and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first step was to clean and filter the 11k Hands Dataset. This step also included making the data into the correct datatypes that would be accepted by Tensorflow. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imports we used to process and clean our data are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 11k Hands Dataset includes images of hands that have nail polish, accessories (such as rings), and abnormalities. For our project, we filtered out each image of a hand that included these features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read csv into a dataframe\n",
    "Handdf = pd.read_csv('HandInfo - HandInfo.csv')\n",
    "\n",
    "#filter out hands with nail polish, accessories, and irregularities\n",
    "Handdf = Handdf.query('accessories == 0 & nailPolish == 0 & irregularities == 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our goal is to teach the computer to decipher between left and right palm and dorsal facing hands, we converted each aspect of hand label into a corresponding number. Images of dorsal right hands have the label 0. Images of dorsal left hands have the label 1. Images of palmar right hands have the label 2. Finally, images of palmar left hands have the label 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#access a panda series of image names and the aspect of each hand (refers right/left dorsal/palmar)\n",
    "imageNameList = Handdf['imageName']\n",
    "imageLabelsFull = Handdf['aspectOfHand']\n",
    "\n",
    "#create an empty list of image labels \n",
    "imageLabels = []\n",
    "\n",
    "#rename each label with its corresponding number\n",
    "for entry in imageLabelsFull:\n",
    "    if entry == 'dorsal right':\n",
    "        imageLabels.append(0)\n",
    "    elif entry == 'dorsal left':\n",
    "        imageLabels.append(1)\n",
    "    elif entry == 'palmar right':\n",
    "        imageLabels.append(2)\n",
    "    elif entry == 'palmar left':\n",
    "        imageLabels.append(3)\n",
    "    else:\n",
    "        print(\"Not a part of the four categories\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we relabeled each image to its correspoonding number, we divided up the images into training and testing groups. After filtering the data, we had approximately 7000 images left. We decided to have 5000 training images and approximately 2000 testing images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set the number of training images\n",
    "numTrainingImages = 5000\n",
    "\n",
    "#makes a list of all training images and training labels\n",
    "trainingImageNames = imageNameList[:numTrainingImages]\n",
    "trainingLabels = imageLabels[:numTrainingImages]\n",
    "\n",
    "#makes a list of all testing images and testing labels\n",
    "testImageNames = imageNameList[numTrainingImages:]\n",
    "testLabels = imageLabels[numTrainingImages:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use tensorflow, our data must be in a numpy array. We used a for loop to go through each image in the training and testing data. The for loop makes each image black and white. It also resizes each image to 128x128. Next, we make each image into a numpy array and add each array into an array of testing and training images. We also have to make the list of testing and training labels into an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'trainingImageNames' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f1527f1f1d52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#training images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrainingImages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainingImageNames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mimageName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Users\\hvclab\\Desktop\\Creating-GANs\\Hands\\\\\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mimageName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainingImageNames' is not defined"
     ]
    }
   ],
   "source": [
    "#training images\n",
    "trainingImages = []\n",
    "for image in trainingImageNames:\n",
    "    imageName = str(image)\n",
    "    if os.path.isfile(r\"C:\\Users\\hvclab\\Desktop\\Creating-GANs\\Hands\\\\\" + imageName):\n",
    "        image = Image.open(r\"C:\\Users\\hvclab\\Desktop\\Creating-GANs\\Hands\\\\\" + imageName).convert('L').resize((128,128))\n",
    "        data = asarray(image)\n",
    "        trainingImages.append(data)\n",
    "        \n",
    "#testing images\n",
    "testImages = []\n",
    "for image in testImageNames:\n",
    "    imageName = str(image)\n",
    "    if os.path.isfile(r\"C:\\Users\\hvclab\\Desktop\\Creating-GANs\\Hands\\\\\" + imageName):\n",
    "        image = Image.open(r\"C:\\Users\\hvclab\\Desktop\\Creating-GANs\\Hands\\\\\" + imageName).convert('L').resize((128,128))\n",
    "        data = asarray(image)\n",
    "        testImages.append(data)\n",
    "        \n",
    "#training and testing labels \n",
    "trainingImages = np.asarray(trainingImages)\n",
    "testImages = np.asarray(testImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training"
   ]
  },
  {
   "source": [],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.1 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "interpreter": {
   "hash": "359343f488ee02b9580848601f3c5cf0b20056a4149dc17f778662caba939f41"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}